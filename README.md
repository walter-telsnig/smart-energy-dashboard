âš¡âš¡âš¡ Smart Energy Dashboard â€” Roadmap & Architecture Overviewâš¡âš¡âš¡

[![Smart Energy Dashboard CI](https://github.com/walter-telsnig/smart-energy-dashboard/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/walter-telsnig/smart-energy-dashboard/actions/workflows/ci.yml?query=branch%3Amain)

[![Hello Python](https://github.com/walter-telsnig/smart-energy-dashboard/actions/workflows/hello-python.yml/badge.svg)](https://github.com/walter-telsnig/smart-energy-dashboard/actions/workflows/hello-python.yml)

This project follows a **monolithic (modular monolith)** architecture built in Python 3.13 with FastAPI, SQLAlchemy, Alembic, and Docker.  
It adheres to the **layered architecture** and **component principles** (ADP, SDP, SAP) from the *Software Architecture/AES* course at AAU Klagenfurt.

### ğŸ§± Layered Architecture

| Layer | Description | Example Modules |
|-------|--------------|----------------|
| **Presentation** | Handles user and system interaction (API, visualization) | `app/`, `ui/` |
| **Application** | Coordinates use cases and orchestrates domain logic | `modules/accounts/application/` |
| **Domain** | Encapsulates core business logic and entities | `modules/accounts/domain/` |
| **Infrastructure** | Handles persistence, external APIs, and system integration | `platform/`, `modules/*/infrastructure/` |

Each layer depends **inward** (Presentation â†’ Application â†’ Domain â†’ Infrastructure), ensuring **low coupling** and **high cohesion** according to ADP, SDP, and DIP.

---

## ğŸ› ï¸ Project Milestones

### **Milestone 1 â€” API Layer & Accounts (CRUD skeleton)**
Implement FastAPI routes for the first domain (`accounts`):
- REST endpoints (`/api/v1/accounts/`)
- DTOs and use cases (`CreateUser`, `ListUsers`)
- Unit and integration tests via Pytest  
ğŸ§­ *Applies SRP, DIP, ADP â€” clear separation between API, application logic, and persistence.*

<Update 2025-10-19>
| Layer                           | Status | Key Design Principle                       |
| ------------------------------- | ------ | ------------------------------------------ |
| **Domain (entities)**           | âœ…      | SRP â€” pure business logic only             |
| **Application (use-cases)**     | âœ…      | DIP â€” depends on ports, not infrastructure |
| **Infrastructure (SQLAlchemy)** | âœ…      | ADP â€” depends inward, implements ports     |
| **API (FastAPI routes)**        | âœ…      | SRP + DIP â€” thin HTTP adapters only        |
| **DB migrations (Alembic)**     | âœ…      | version-controlled schema                  |
| **Tests**                       | âœ…      | unit + integration pass cleanly            |

# PV Test / mockup 
Under infra/data/pv/pv_2026_hourly.csv we have prepared initial data for PV production for the year 2026 in hourly resolution.
With uvicorn app.main:app --reload one can start the app and open the Swagger UI under http://127.0.0.1:8000/docs
There you'll fine the API endpoint GET /api/v1/pv (default key pv_2026_hourly).
It will return a JSON file for the whole year 2026 (8760 points).

![Smart Energy Dashboard Preview](docs/images/Swagger_preview.png)

![Smart Energy Dashboard Preview](docs/images/pv_endpoints.png)

## Comments regarding principles from the lecture notes:
- **SRP**: UI stays thin; CSV loading isolated in `infra/pv/repository_csv.py`.
- **DIP**: API depends on `PVRepositoryPort` via the adapter (we can later swap CSV for DB or live API â€” live API is unlikely).
- **ADP**: The dependency arrows point inward (API â†’ modules). Infra implements ports; domain is independent.
---

### **Milestone 2 â€” Quality Gates (CI, typing, logging, errors)**
Add static analysis, logging, and error management:
- GitHub Actions pipeline (Ruff, Mypy, Pytest)
- Centralized logging and error handling
- Strict type checking (`mypy.ini`)
ğŸ§­ *Applies SDP and SAP â€” stability and abstraction increase toward inner layers.*

---

### **Milestone 3 â€” Postgres + Docker Compose (DevOps slice)**
Introduce containerized deployment:
- Dockerfile and `docker-compose.yml` (API + Postgres)
- Environment configuration via `.env`
- Alembic migrations executed in container startup  
ğŸ§­ *Applies CRP (Common Reuse Principle) and CCP (Common Closure Principle) â€” deploy related modules together.*

---

### **Milestone 4 â€” Authentication (JWT) & Demo Readiness**
Add user authentication and secure access:
- User registration and token endpoints (`/auth/register`, `/auth/token`)
- JWT-based authorization and protected routes
- Clean OpenAPI documentation and ready-to-demo instance  
ğŸ§­ *Applies OCP and DIP â€” authentication is extendable and decoupled from domain logic.*

---

### **Milestone 5 â€” Visualization & Analytics (Streamlit Dashboard)**
Add an interactive, data-driven dashboard for energy insights.

**Goals**
- Implement `ui/dashboard_app.py` using **Streamlit**
- Visualize time series, forecasts, and KPIs (e.g., PV output, storage utilization)
- Communicate with the FastAPI backend via REST or read directly from the database
- Provide dynamic controls (date filters, sliders, charts)  
ğŸ§­ *Applies SRP, DIP, SDP â€” UI focuses purely on visualization while depending on stable API abstractions.*






## ğŸ§­ Project Setup (for collaborators)

### âš™ï¸ Prerequisites
- ğŸ **Python 3.13**
- ğŸ’» **VS Code** + Git
- ğŸ³ **Docker Desktop** *(optional; only needed from Milestone 3 onward)*

---

### ğŸ§© 1ï¸âƒ£ Clone the repository

git clone https://github.com/walter-telsnig/smart-energy-dashboard.git \
cd smart-energy-dashboard

### ğŸª¶ 2ï¸âƒ£ Create and activate the virtual environment

python -m venv .venv \
.venv\Scripts\Activate.ps1

### ğŸ“¦ 3ï¸âƒ£ Install dependencies
pip install -U pip \
pip install -r requirements.txt

### âš™ï¸ 4ï¸âƒ£ Configure environment
Create a .env file (or copy from .env.example) with:

SED_DB_URL=sqlite:///./dev.db
API_BASE=http://localhost:8000/api/v1

ğŸ’¡ SQLite is used for local development.
Later milestones (M3 +) switch to Postgres via Docker Compose.

### ğŸš€ 5ï¸âƒ£ Run the API
python -m uvicorn app.main:create_app --factory --reload --port 8000

Check:

âœ… Health: http://localhost:8000/health
ğŸ“˜ Docs: http://localhost:8000/docs


### ğŸ’¡ 6ï¸âƒ£ Run the Streamlit UI
.venv\Scripts\activate \
streamlit run ui/app.py

ğŸŒ UI available at: http://localhost:8501

### ğŸ§ª 7ï¸âƒ£ Run tests
pytest -q
âœ… Expected: 5 passed in X.XXs

### ğŸ§­ 8ï¸âƒ£ Run via VS Code

Start either service with F5 using the predefined launch configurations:

â–¶ï¸ API (Uvicorn, factory)

â–¶ï¸ UI (Streamlit)

### ğŸ§° 9ï¸âƒ£ ( Optional ) Run via Docker Compose
docker compose up

Services:

âš™ï¸ API â†’ http://localhost:8000/health
ğŸ“Š UI â†’ http://localhost:8501


### ğŸ§± Folder Overview
app/        FastAPI routers & app entrypoint
modules/    Domain logic (e.g., accounts model)
infra/      Database engine/session, CSV data, migrations
core/       Cross-cutting settings, logging, error handling
ui/         Streamlit demo (read-only dashboard)
tests/      Unit + integration tests
docs/       Architecture notes & ADRs

### ğŸ” Staying up to date
git pull origin main

And after you changed something:
git add .
git commit -m "feat: <your message>"
git push

---

### ğŸ’¾ Local development database

By default, the project uses a lightweight **SQLite** database named `dev.db`
stored in the project root.

- It will be **created automatically** when you first start the API.
- You can inspect it using any SQLite viewer (e.g., VS Code â€œSQLite Viewerâ€ extension).
- It is **not versioned** â€” itâ€™s ignored by `.gitignore` and safe to delete anytime.
- For a clean start:
  ```powershell
  Remove-Item dev.db


### Docker Tutorial (Sabrina)
______________________________________________________________________________________
Tutorial Docker Postgres (there are just informations about Postgres in Docker): https://www.datacamp.com/tutorial/postgresql-docker


Postgres-Infos are in the docker-compose.yml file.


HOW TO INSTALL the Postgres Docker Container:
1. IMPORTANT: Check if you have pulled the commit with the docker-compose.yml file.
2. Go to where you have save the GitHub repo
3. Open there CMD
4. Use the command docker copose up -d
5. Check if the container is runing with the command docker ps


HOW TO WORK WITH IT:
1. Start container: docker start postgres-db
2. Stop container: docker stop postgres-db


Variations to Query something: \
a. Use PSQL in Command: docker exec -it postgres-db psql -U postgres -d pv-db \
b. Use pgAdmin


HOW TO ADD the server to pgAdmin(In Case my description isn't clearly. It is also described at the tutorial page: https://www.datacamp.com/tutorial/postgresql-docker?dc_referrer=https%3A%2F%2Fwww.google.com%2F#connecting-using-a-gui-tool-manyd):
1. Right Click at Servers
2. Register->Server
3. In General tab, write the name of the server in the field "Name"
4. In Connection, write "localhost" in the field "Host name/address" and the password in field "Password"
5. Click at the Save Button and the Server is connected with pgAdmin


Note: If you add data in the database, please save the queries as SQL file in the GitHub repo. So we have the same data.
